#pragma once

#include <torch/csrc/lazy/core/ir.h>
#include <torch/csrc/lazy/core/ir_builder.h>
#include <torch/csrc/lazy/core/internal_ops/ltc_ops.h>
#include <torch/csrc/lazy/core/shape_inference.h>
#include <torch/csrc/lazy/ts_backend/ts_node.h>

// This file contains autogenerated LazyTensor Non Native IR nodes

namespace torch {
namespace lazy {

class Scalar : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::prim::Constant);
  }

  Scalar(const at::Scalar& value, const at::ScalarType& type)
      : TsNode(
              Scalar::ClassOpKind(),
              OpList{},
              compute_shape_scalar(value, type),
              /* num_outputs */ 1,
              torch::lazy::MHash(value, type)),
        value(value),
        type(type)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", value=" << value;
    ss << ", type=" << type;
    return ss.str();
  }

  

  bool CanBeReused(const at::Scalar& value, const at::ScalarType& type) const;

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  at::Scalar value;
  at::ScalarType type;
  

};

class Expand : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::expand);
  }

  Expand(const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const bool& is_scalar_expand)
      : TsNode(
              Expand::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_expand(operand(0), size, is_scalar_expand)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(size, is_scalar_expand)),
        size(size),
        is_scalar_expand(is_scalar_expand)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", size=" << size;
    ss << ", is_scalar_expand=" << is_scalar_expand;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const bool& is_scalar_expand) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->size == size &&
        this->is_scalar_expand == is_scalar_expand);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> size;
  bool is_scalar_expand;
  

};

class View : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::view);
  }

  View(const torch::lazy::Value& input, const ::std::vector<int64_t>& output_size)
      : TsNode(
              View::ClassOpKind(),
              OpList{input},
              compute_shape_view(input, output_size),
              /* num_outputs */ 1,
              torch::lazy::MHash(output_size)),
        output_size(output_size)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", output_size=" << output_size;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& output_size) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->output_size == output_size);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> output_size;
  

};

class Cast : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(ltc_cast);
  }

  Cast(const torch::lazy::Value& input, const at::ScalarType& dtype, const c10::optional<at::ScalarType>& stype)
      : TsNode(
              Cast::ClassOpKind(),
              OpList{input},
              compute_shape_cast(input, dtype, stype),
              /* num_outputs */ 1,
              torch::lazy::MHash(dtype, stype)),
        dtype(dtype),
        stype(stype)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", dtype=" << dtype;
    if (stype.has_value()) {
      ss << ", stype=" << stype.value();
    } else {
      ss << ", stype=null";
    }
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const at::ScalarType& dtype, const c10::optional<at::ScalarType>& stype) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->dtype == dtype &&
        ((!this->stype&&!stype) || (this->stype&&stype && *(this->stype) == *stype)));
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  at::ScalarType dtype;
  c10::optional<at::ScalarType> stype;
  

};

class AsStridedViewUpdate : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(ltc_as_strided_view_update);
  }

  AsStridedViewUpdate(const torch::lazy::Value& target, const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const ::std::vector<int64_t>& stride, const int64_t& storage_offset)
      : TsNode(
              AsStridedViewUpdate::ClassOpKind(),
              OpList{target, input},
              [&](){ return compute_shape_as_strided_view_update(operand(0), operand(1), size, stride, storage_offset)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(size, stride, storage_offset)),
        size(size),
        stride(stride),
        storage_offset(storage_offset)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", size=" << size;
    ss << ", stride=" << stride;
    ss << ", storage_offset=" << storage_offset;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& target, const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const ::std::vector<int64_t>& stride, const int64_t& storage_offset) const {
    size_t i = 0;
    return (operand(i++) == target &&
        operand(i++) == input &&
        this->size == size &&
        this->stride == stride &&
        this->storage_offset == storage_offset);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> size;
  ::std::vector<int64_t> stride;
  int64_t storage_offset;
  

};

class AsStrided : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::as_strided);
  }

  AsStrided(const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const ::std::vector<int64_t>& stride, const int64_t& storage_offset)
      : TsNode(
              AsStrided::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_as_strided(operand(0), size, stride, storage_offset)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(size, stride, storage_offset)),
        size(size),
        stride(stride),
        storage_offset(storage_offset)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", size=" << size;
    ss << ", stride=" << stride;
    ss << ", storage_offset=" << storage_offset;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& size, const ::std::vector<int64_t>& stride, const int64_t& storage_offset) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->size == size &&
        this->stride == stride &&
        this->storage_offset == storage_offset);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> size;
  ::std::vector<int64_t> stride;
  int64_t storage_offset;
  

};

class DiagonalViewUpdate : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(ltc_diagonal_view_update);
  }

  DiagonalViewUpdate(const torch::lazy::Value& target, const torch::lazy::Value& input, const int64_t& offset, const int64_t& dim1, const int64_t& dim2)
      : TsNode(
              DiagonalViewUpdate::ClassOpKind(),
              OpList{target, input},
              compute_shape_diagonal_view_update(target, input, offset, dim1, dim2),
              /* num_outputs */ 1,
              torch::lazy::MHash(offset, dim1, dim2)),
        offset(offset),
        dim1(dim1),
        dim2(dim2)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", offset=" << offset;
    ss << ", dim1=" << dim1;
    ss << ", dim2=" << dim2;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& target, const torch::lazy::Value& input, const int64_t& offset, const int64_t& dim1, const int64_t& dim2) const {
    size_t i = 0;
    return (operand(i++) == target &&
        operand(i++) == input &&
        this->offset == offset &&
        this->dim1 == dim1 &&
        this->dim2 == dim2);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  int64_t offset;
  int64_t dim1;
  int64_t dim2;
  

};

class Diagonal : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::diagonal);
  }

  Diagonal(const torch::lazy::Value& input, const int64_t& offset, const int64_t& dim1, const int64_t& dim2)
      : TsNode(
              Diagonal::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_diagonal(operand(0), offset, dim1, dim2)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(offset, dim1, dim2)),
        offset(offset),
        dim1(dim1),
        dim2(dim2)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", offset=" << offset;
    ss << ", dim1=" << dim1;
    ss << ", dim2=" << dim2;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const int64_t& offset, const int64_t& dim1, const int64_t& dim2) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->offset == offset &&
        this->dim1 == dim1 &&
        this->dim2 == dim2);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  int64_t offset;
  int64_t dim1;
  int64_t dim2;
  

};

class NarrowViewUpdate : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(ltc_narrow_view_update);
  }

  NarrowViewUpdate(const torch::lazy::Value& input, const torch::lazy::Value& source, const ::std::vector<int64_t>& base_indices)
      : TsNode(
              NarrowViewUpdate::ClassOpKind(),
              OpList{input, source},
              [&](){ return compute_shape_narrow_view_update(operand(0), operand(1), base_indices)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(base_indices)),
        base_indices(base_indices)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", base_indices=" << base_indices;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const torch::lazy::Value& source, const ::std::vector<int64_t>& base_indices) const {
    size_t i = 0;
    return (operand(i++) == input &&
        operand(i++) == source &&
        this->base_indices == base_indices);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> base_indices;
  

};

class Narrow : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::narrow);
  }

  Narrow(const torch::lazy::Value& input, const ::std::vector<int64_t>& base_indices, const ::std::vector<int64_t>& sizes)
      : TsNode(
              Narrow::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_narrow(operand(0), base_indices, sizes)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(base_indices, sizes)),
        base_indices(base_indices),
        sizes(sizes)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", base_indices=" << base_indices;
    ss << ", sizes=" << sizes;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& base_indices, const ::std::vector<int64_t>& sizes) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->base_indices == base_indices &&
        this->sizes == sizes);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> base_indices;
  ::std::vector<int64_t> sizes;
  

};

class Permute : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::permute);
  }

  Permute(const torch::lazy::Value& input, const ::std::vector<int64_t>& dims)
      : TsNode(
              Permute::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_permute(operand(0), dims)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(dims)),
        dims(dims)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", dims=" << dims;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& dims) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->dims == dims);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> dims;
  

};

class Resize : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::resize);
  }

  Resize(const torch::lazy::Value& input, const ::std::vector<int64_t>& size)
      : TsNode(
              Resize::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_resize(operand(0), size)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(size)),
        size(size)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", size=" << size;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const ::std::vector<int64_t>& size) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->size == size);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  ::std::vector<int64_t> size;
  

};

class SelectViewUpdate : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(ltc_select_view_update);
  }

  SelectViewUpdate(const torch::lazy::Value& target, const torch::lazy::Value& source, const int64_t& dim, const int64_t& start, const int64_t& end, const int64_t& stride)
      : TsNode(
              SelectViewUpdate::ClassOpKind(),
              OpList{target, source},
              compute_shape_select_view_update(target, source, dim, start, end, stride),
              /* num_outputs */ 1,
              torch::lazy::MHash(dim, start, end, stride)),
        dim(dim),
        start(start),
        end(end),
        stride(stride)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", dim=" << dim;
    ss << ", start=" << start;
    ss << ", end=" << end;
    ss << ", stride=" << stride;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& target, const torch::lazy::Value& source, const int64_t& dim, const int64_t& start, const int64_t& end, const int64_t& stride) const {
    size_t i = 0;
    return (operand(i++) == target &&
        operand(i++) == source &&
        this->dim == dim &&
        this->start == start &&
        this->end == end &&
        this->stride == stride);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  int64_t dim;
  int64_t start;
  int64_t end;
  int64_t stride;
  

};

class Select : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::select);
  }

  Select(const torch::lazy::Value& input, const int64_t& dim, const int64_t& start, const int64_t& end, const int64_t& stride)
      : TsNode(
              Select::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_select(operand(0), dim, start, end, stride)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(dim, start, end, stride)),
        dim(dim),
        start(start),
        end(end),
        stride(stride)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", dim=" << dim;
    ss << ", start=" << start;
    ss << ", end=" << end;
    ss << ", stride=" << stride;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const int64_t& dim, const int64_t& start, const int64_t& end, const int64_t& stride) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->dim == dim &&
        this->start == start &&
        this->end == end &&
        this->stride == stride);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  int64_t dim;
  int64_t start;
  int64_t end;
  int64_t stride;
  

};

class Squeeze : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::squeeze);
  }

  Squeeze(const torch::lazy::Value& input, const int64_t& dim)
      : TsNode(
              Squeeze::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_squeeze(operand(0), dim)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(dim)),
        dim(dim)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", dim=" << dim;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const int64_t& dim) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->dim == dim);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  int64_t dim;
  

};

class Unsqueeze : public TsNode {
 public:
  static torch::lazy::OpKind ClassOpKind() {
    return torch::lazy::OpKind(at::aten::unsqueeze);
  }

  Unsqueeze(const torch::lazy::Value& input, const int64_t& dim)
      : TsNode(
              Unsqueeze::ClassOpKind(),
              OpList{input},
              [&](){ return compute_shape_unsqueeze(operand(0), dim)[0]; },
              /* num_outputs */ 1,
              torch::lazy::MHash(dim)),
        dim(dim)
  {
    
  }

  std::string ToString() const override {
    std::stringstream ss;
    ss << TsNode::ToString();
    ss << ", dim=" << dim;
    return ss.str();
  }

  

  bool CanBeReused(const torch::lazy::Value& input, const int64_t& dim) const {
    size_t i = 0;
    return (operand(i++) == input &&
        this->dim == dim);
  }

  
  torch::lazy::TSOpVector Lower(
      std::shared_ptr<torch::jit::GraphFunction> function,
      torch::lazy::TSLoweringContext* loctx) const override;

  int64_t dim;
  

};

} // namespace lazy
} // namespace torch
